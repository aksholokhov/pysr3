{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![](https://img.shields.io/pypi/l/skmixed)\n",
    "![](https://img.shields.io/github/workflow/status/aksholokhov/skmixed/Testing%20and%20Coverage/sr3)\n",
    "![](https://img.shields.io/readthedocs/skmixed)\n",
    "![](https://img.shields.io/codecov/c/github/aksholokhov/skmixed/sr3?flag=unittests)\n",
    "[![Codacy Badge](https://app.codacy.com/project/badge/Grade/749695b3c6fd43bb9fdb499ec0ace67b)](https://www.codacy.com/gh/aksholokhov/skmixed/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=aksholokhov/skmixed&amp;utm_campaign=Badge_Grade)\n",
    "\n",
    "# SR3: Features Selection with Relaxed Regularization Framework."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quickstart\n",
    "\n",
    "SR3 is a library designed for feature selection via Sparse Relaxed Regularized Regression (SR3) framework."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# !pip install skmixed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 300 objects and 500 features; \n",
      "The vector of true parameters contains 55 non-zero elements out of 500.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skmixed.linear.problems import LinearProblem\n",
    "\n",
    "# Create a sample dataset\n",
    "seed = 42\n",
    "num_objects = 300\n",
    "num_features = 500\n",
    "np.random.seed(seed)\n",
    "# create a vector of true model's coefficients\n",
    "true_x = np.random.choice(2, size=num_features, p=np.array([0.9, 0.1]))\n",
    "# create sample data\n",
    "a = 10*np.random.randn(num_objects, num_features)\n",
    "b = a.dot(true_x) + np.random.randn(num_objects)\n",
    "\n",
    "print(f\"The dataset has {a.shape[0]} objects and {a.shape[1]} features; \\n\"\n",
    "      f\"The vector of true parameters contains {sum(true_x != 0)} non-zero elements out of {num_features}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model found 55 out of 55 features correctly, but also chose 2 extra irrelevant features. \n",
      "The best parameter is {'lam': 0.15055187290939537}\n"
     ]
    }
   ],
   "source": [
    "# Automatic features selection using information criterion\n",
    "from skmixed.linear.models import LinearL1ModelSR3\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "model = LinearL1ModelSR3(logger_keys=('aic', 'bic'))\n",
    "params = {\n",
    "    #\"el\": loguniform(1e-2, 1e2),\n",
    "    \"lam\": loguniform(1e-1, 1e2)\n",
    "}\n",
    "selector = RandomizedSearchCV(estimator=model,\n",
    "                              param_distributions=params,\n",
    "                              n_iter=50,\n",
    "                              scoring=lambda clf, X, y: -clf.logger_.get('bic'))\n",
    "\n",
    "selector.fit(a, b)\n",
    "maybe_x = selector.best_estimator_.coef_['x']\n",
    "tn, fp, fn, tp = confusion_matrix(true_x, maybe_x != 0).ravel()\n",
    "\n",
    "print(f\"The model found {tp} out of {tp + fn} features correctly, but also chose {fp} extra irrelevant features. \\n\"\n",
    "      f\"The best parameter is {selector.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear Mixed-Effects Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model found 9 out of 10 correct fixed features, and also chose 2 out of 9 extra irrelevant fixed features. \n",
      "It also identified 5 out of 5 random effects correctly, and got 0 out of 15 non-present random effects\n"
     ]
    }
   ],
   "source": [
    "from skmixed.lme.models import L1LmeModelSR3\n",
    "from skmixed.lme.problems import LMEProblem, LMEStratifiedShuffleSplit\n",
    "\n",
    "problem, true_parameters = LMEProblem.generate(groups_sizes=[10]*6,\n",
    "                                               features_labels=[\"fixed+random\"]*20,\n",
    "                                               beta=np.array([0, 1]*10),\n",
    "                                               gamma=np.array([0, 0, 0, 1]*5),\n",
    "                                               obs_var=0.1)\n",
    "x, y, columns_labels = problem.to_x_y()\n",
    "\n",
    "model = L1LmeModelSR3()\n",
    "\n",
    "params = {\n",
    "    \"lam\": loguniform(1e-3, 1e3)\n",
    "}\n",
    "selector = RandomizedSearchCV(estimator=model,\n",
    "                              param_distributions=params,\n",
    "                              n_iter=10,\n",
    "                              cv=LMEStratifiedShuffleSplit(n_splits=2, test_size=0.5,\n",
    "                                                           random_state=seed,\n",
    "                                                           columns_labels=columns_labels),\n",
    "                              scoring=lambda clf, x, y: -clf.get_information_criterion(x, y, columns_labels=columns_labels, ic=\"muller_ic\"),\n",
    "                              random_state=seed,\n",
    "                              n_jobs=20\n",
    "                              )\n",
    "selector.fit(x, y, columns_labels=columns_labels)\n",
    "best_model = selector.best_estimator_\n",
    "\n",
    "maybe_beta = best_model.coef_[\"beta\"]\n",
    "maybe_gamma = best_model.coef_[\"gamma\"]\n",
    "ftn, ffp, ffn, ftp = confusion_matrix(true_parameters[\"beta\"], abs(maybe_beta) > 1e-2).ravel()\n",
    "rtn, rfp, rfn, rtp = confusion_matrix(true_parameters[\"gamma\"], abs(maybe_gamma) > 1e-2).ravel()\n",
    "\n",
    "print(f\"The model found {ftp} out of {ftp + ffn} correct fixed features, and also chose {ffp} out of {ftn + ffn} extra irrelevant fixed features. \\n\"\n",
    "      f\"It also identified {rtp} out of {rtp + rfn} random effects correctly, and got {rfp} out of {rtn + rfn} non-present random effects. \\n\"\n",
    "      f\"The best sparsity parameter is {selector.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_skmixed)",
   "language": "python",
   "name": "conda_skmixed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}