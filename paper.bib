@article{Buscemi2019Survey,
abstract = {Linear mixed-effects models are a class of models widely used for analyzing different types of data: longitudinal, clustered and panel data. Many fields, in which a statistical methodology is required, involve the employment of linear mixed models, such as biology, chemistry, medicine, finance and so forth. One of the most important processes, in a statistical analysis, is given by model_name selection. Hence, since there are a large number of linear mixed model_name selection procedures available in the literature, a pressing issue is how to identify the best approach to adopt in a specific case. We outline mainly all approaches focusing on the part of the model_name subject to selection (fixed and/or random), the dimensionality of models and the structure of variance and covariance matrices, and also, wherever possible, the existence of an implemented application of the methodologies set out.},
annote = {The most up-to-date literature review found on this issue.},
author = {Buscemi, Simona and Plaia, Antonella},
doi = {10.1007/s10182-019-00359-z},
file = {:Users/aksh/Documents/Papers/2020/Buscemi, Plaia/Model selection in linear mixed-effect models/Buscemi, Plaia - 2020 - Model selection in linear mixed-effect models.pdf:pdf},
issn = {1863-8171},
journal = {AStA Advances in Statistical Analysis},
keywords = {AIC,BIC,LASSO,Linear mixed model_name,MCP,MDL,Mixed model_name selection,Shrinkage methods},
mendeley-groups = {Feature/Effects Selection,Surveys Summaries Overviews},
month = {dec},
number = {4},
pages = {529--575},
publisher = {Springer Berlin Heidelberg},
title = {{Model selection in linear mixed-effect models}},
url = {https://doi.org/10.1007/s10182-019-00359-z http://link.springer.com/10.1007/s10182-019-00359-z},
volume = {104},
year = {2020}
}

@article{zheng2018unified,
  title={A unified framework for sparse relaxed regularized regression: SR3},
  author={Zheng, Peng and Askham, Travis and Brunton, Steven L and Kutz, J Nathan and Aravkin, Aleksandr Y},
  journal={IEEE Access},
  volume={7},
  pages={1404--1423},
  year={2018},
  publisher={IEEE},
  doi = {10.1109/ACCESS.2018.2886528}
}

@article{sholokhov2022relaxation,
  title={A Relaxation Approach to Feature Selection for Linear Mixed Effects Models},
  author={Sholokhov, Aleksei and Burke, James V and Santomauro, Damian F and Zheng, Peng and Aravkin, Aleksandr},
  journal={arXiv preprint arXiv:2205.06925},
  year={2022},
  doi={10.48550/arXiv.2205.06925}
}
@article{aravkin2022relaxationb,
  title={Analysis of Relaxation Methods for Feature Selection in Mixed Effects Models},
  author={Aravkin, Aleksandr and Burke, James and Sholokhov, Aleksei and Zheng, Peng},
  journal={arXiv preprint arXiv:2209.10575},
  year={2022},
  doi={10.48550/arXiv.2209.10575}
}

@article{baraldi2019basis,
  title={Basis pursuit denoise with nonsmooth constraints},
  author={Baraldi, Robert and Kumar, Rajiv and Aravkin, Aleksandr},
  journal={IEEE Transactions on Signal Processing},
  volume={67},
  number={22},
  pages={5811--5823},
  year={2019},
  publisher={IEEE},
  doi={10.1109/tsp.2019.2946029}
}

@article{murray2020global,
  title={Global burden of 87 risk factors in 204 countries and territories, 1990--2019: a systematic analysis for the Global Burden of Disease Study 2019},
  author={Murray, Christopher JL and Aravkin, Aleksandr Y and Zheng, Peng and Abbafati, Cristiana and Abbas, Kaja M and Abbasi-Kangevari, Mohsen and Abd-Allah, Foad and Abdelalim, Ahmed and Abdollahi, Mohammad and Abdollahpour, Ibrahim and others},
  journal={The Lancet},
  volume={396},
  number={10258},
  pages={1223--1249},
  year={2020},
  publisher={Elsevier},
  doi={10.1016/S0140-6736(20)30752-2},
}


@article{schelldorfer2014glmmlasso,
  title={Glmmlasso: an algorithm for high-dimensional generalized linear mixed models using L1-penalization},
  author={Schelldorfer, J{\"u}rg and Meier, Lukas and B{\"u}hlmann, Peter},
  journal={Journal of Computational and Graphical Statistics},
  volume={23},
  number={2},
  pages={460--477},
  year={2014},
  publisher={Taylor \& Francis},
  doi={10.1080/10618600.2013.773239}
}


@article{li2020survey,
  title={A survey on sparse learning models for feature selection},
  author={Li, Xiaoping and Wang, Yadi and Ruiz, Rub{\'e}n},
  journal={IEEE transactions on cybernetics},
  year={2020},
  publisher={IEEE},
  doi={10.1109/TCYB.2020.2982445}
}

@article{miao2016survey,
  title={A survey on feature selection},
  author={Miao, Jianyu and Niu, Lingfeng},
  journal={Procedia Computer Science},
  volume={91},
  pages={919--926},
  year={2016},
  publisher={Elsevier},
  doi={10.1016/j.procs.2016.07.111}
}

@article{Zheng2020,
abstract = {We develop and analyze a new 'relax-and-split' (RS) approach for inverse problems modeled using nonsmooth nonconvex optimization formulations. RS uses a relaxation technique together with partial minimization, and brings classic techniques including direct factorization, matrix decompositions, and fast iterative methods to bear on nonsmooth nonconvex problems. We also extend the approach to robustify any such inverse problem through trimming, a mechanism that robustifies inverse problems to measurement outliers. We then show practical performance of RS and trimmed RS (TRS) on a diverse set of problems, including: (1) phase retrieval, (2) semi-supervised classification, (3) stochastic shortest path problems, and (4) nonconvex clustering. RS/TRS are easy to implement, competitive with existing methods, and show promising results on difficult inverse problems with nonsmooth and nonconvex features.},
author = {Zheng, Peng and Aravkin, Aleksandr},
doi = {10.1088/1361-6420/aba417},
file = {:Users/aksh/Documents/Papers/2020/Zheng, Aravkin/Relax-and-split method for nonconvex inverse problems/Zheng, Aravkin - 2020 - Relax-and-split method for nonconvex inverse problems.pdf:pdf},
issn = {13616420},
journal = {Inverse Problems},
keywords = {nonconvex optimization,nonsmooth models,splitting methods},
mendeley-groups = {Relax-and-Split examples},
number = {9},
publisher = {IOP Publishing},
title = {{Relax-and-split method for nonconvex inverse problems}},
volume = {36},
year = {2020}
}

@article{Mendible2020,
abstract = {We develop an unsupervised machine learning algorithm for the automated discovery and identification of traveling waves in spatiotemporal systems governed by partial differential equations (PDEs). Our method uses sparse regression and subspace clustering to robustly identify translational invariances that can be leveraged to build improved reduced-order models (ROMs). Invariances, whether translational or rotational, are well known to compromise the ability of ROMs to produce accurate and/or low-rank representations of the spatiotemporal dynamics. However, by discovering translations in a principled way, data can be shifted into a coordinate systems where quality, low-dimensional ROMs can be constructed. This approach can be used on either numerical or experimental data with or without knowledge of the governing equations. We demonstrate our method on a variety of PDEs of increasing difficulty, taken from the field of fluid dynamics, showing the efficacy and robustness of the proposed approach.},
archivePrefix = {arXiv},
arxivId = {1911.00565},
author = {Mendible, Ariana and Brunton, Steven L. and Aravkin, Aleksandr Y. and Lowrie, Wes and Kutz, J. Nathan},
doi = {10.1007/s00162-020-00529-9},
eprint = {1911.00565},
file = {:Users/aksh/Documents/Papers/2020/Mendible et al/Dimensionality reduction and reduced-order modeling for traveling wave physics/Mendible et al. - 2020 - Dimensionality reduction and reduced-order modeling for traveling wave physics.pdf:pdf},
issn = {14322250},
journal = {Theoretical and Computational Fluid Dynamics},
keywords = {Data decomposition,Reduced-order modeling,Transported quantities,Traveling waves},
number = {4},
pages = {385--400},
title = {{Dimensionality reduction and reduced-order modeling for traveling wave physics}},
volume = {34},
year = {2020}
}

@article{levin2019proof,
  title={A Proof of Principle: Multi-Modality Radiotherapy Optimization},
  author={Levin, Roman and Aravkin, Aleksandr Y and Kim, Minsun},
  journal={arXiv preprint arXiv:1911.05182},
  year={2019},
  doi={10.48550/arXiv.1911.05182}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011},
 doi={10.5555/1953048.2078195}
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
               Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
               Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
               and Jaques Grobler and Robert Layton and Jake VanderPlas and
               Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
  doi = {10.48550/arXiv.1309.0238}
}

@article{schelldorfer2011estimation,
  title={Estimation for high-dimensional linear mixed-effects models using l1-penalization},
  author={Schelldorfer, J{\"u}rg and B{\"u}hlmann, Peter and DE GEER, SARA VAN},
  journal={Scandinavian Journal of Statistics},
  volume={38},
  number={2},
  pages={197--214},
  year={2011},
  publisher={Wiley Online Library},
  doi={10.1111/j.1467-9469.2011.00740.x}
}
